<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/></head><body>Here's the refined code:<br><br>```<br>import scholarly<br><br>def search_publications(query, max_results=10, sort_by='relevance'):<br>    search_query = scholarly.search_pubs(query)<br>    results = list(search_query)[:max_results]<br><br>    if sort_by == 'citations':<br>        <a href="http://results.sort">results.sort</a>(key=lambda x: <a href="http://x.citedby">x.citedby</a>, reverse=True)<br>    elif sort_by == 'year':<br>        <a href="http://results.sort">results.sort</a>(key=lambda x: <a href="http://x.bib">x.bib</a>['year'], reverse=True)<br><br>    publications = []<br>    for result in results:<br>        pub_info = {<br>            'title': <a href="http://result.bib">result.bib</a>['title'],<br>            'authors': <a href="http://result.bib">result.bib</a>['author'],<br>            'year': <a href="http://result.bib">result.bib</a>['year'],<br>            'citations': <a href="http://result.citedby">result.citedby</a>,<br>            'url': <a href="http://result.bib">result.bib</a>['url'],<br>            'abstract': <a href="http://result.bib.get">result.bib.get</a>('abstract', 'Not available'),<br>            'doi': <a href="http://result.bib.get">result.bib.get</a>('doi', 'Not available'),<br>            'publisher': <a href="http://result.bib.get">result.bib.get</a>('publisher', 'Not available'),<br>            'publication': <a href="http://result.bib.get">result.bib.get</a>('publication', 'Not available')<br>        }<br>        <a href="http://publications.append">publications.append</a>(pub_info)<br><br>    return publications<br><br>query = 'deep learning'<br>max_results = 20<br>sort_by = 'citations'  # or 'year' or 'relevance'<br><br>publications = search_publications(query, max_results, sort_by)<br>for pub in publications:<br>    print(pub)<br>```<br><br>This refined code adds the following fields to the `pub_info` dictionary:<br><br>- `doi`<br>- `publisher`<br>- `publication`<br><br>It also uses the `get()` method to handle cases where the abstract, DOI, publisher, or publication are missing. If any of these fields are missing, it will display "Not available" instead of throwing an error.<br><br><br><br><br>Sure! Here's a replication of your code using the `crossrefapi` library to search for research papers and get their metadata such as DOI, title, authors, year, citations, publisher, and publication:<br><br>First, you need to install the `crossrefapi` package (if not already installed) by running:<br><br>```bash<br>pip install crossrefapi<br>```<br><br>Then, you can use the following code to search publications and retrieve their metadata:<br><br>```python<br>from crossrefapi import CrossrefAPI<br><br>def search_publications(query, max_results=10, sort_by='relevance'):<br>    # Initialize Crossref API<br>    crossref = CrossrefAPI()<br><br>    # Search for publications using Crossref API<br>    search_results = <a href="http://crossref.works">crossref.works</a>(query=query, rows=max_results)<br><br>    # Sort based on specified criteria<br>    results = search_results['message']['items']<br><br>    if sort_by == 'citations':<br>        results = sorted(results, key=lambda x: <a href="http://x.get">x.get</a>('is-referenced-by-count', 0), reverse=True)<br>    elif sort_by == 'year':<br>        results = sorted(results, key=lambda x: <a href="http://x.get">x.get</a>('published', {}).get('date-parts', [[0]])[0][0], reverse=True)<br><br>    publications = []<br>    for result in results:<br>        # Collect metadata for each publication<br>        pub_info = {<br>            'title': <a href="http://result.get">result.get</a>('title', ['Not available'])[0],'authors': ', '.join([author['given'] + ' ' + author['family'] for author in <a href="http://result.get">result.get</a>('author', [])]),<br>            'year': <a href="http://result.get">result.get</a>('published', {}).get('date-parts', [[0]])[0][0],<br>            'citations': <a href="http://result.get">result.get</a>('is-referenced-by-count', 'Not available'),<br>            'url': <a href="http://result.get">result.get</a>('URL', 'Not available'),<br>            'abstract': <a href="http://result.get">result.get</a>('abstract', 'Not available'),<br>            'doi': <a href="http://result.get">result.get</a>('DOI', 'Not available'),<br>            'publisher': <a href="http://result.get">result.get</a>('publisher', 'Not available'),<br>            'publication': <a href="http://result.get">result.get</a>('container-title', ['Not available'])[0]<br>        }<br>        <a href="http://publications.append">publications.append</a>(pub_info)<br><br>    return publications<br><br>Example usage<br>query = 'deep learning'<br>max_results = 20<br>sort_by = 'citations'  # or 'year' or 'relevance'<br><br>publications = search_publications(query, max_results, sort_by)<br><br>Print each publication<br>for pub in publications:<br>    print(pub)<br>.<br><br><br>Here's the updated code:<br><br>```<br>Got it! Here is a simplified version of your script without additional error handling, extra features like multiple authors, and PDF link extraction. The code will just extract basic metadata using the DOI from CrossRef and return it in a simple format.<br><br>Simplified Python Script:<br><br>```python<br>from crossrefapi import CrossRefAPI<br><br>Initialize the CrossRef API client<br>cr = CrossRefAPI()<br><br>def get_publication_by_doi(doi):<br>    # Fetch publication details using the DOI<br>    result = <a href="http://cr.works">cr.works</a>(ids=doi)<br><br>    # Extract publication information<br>    if result['message']['items']:<br>        item = result['message']['items'][0]<br><br>        pub_info = {<br>            'title': <a href="http://item.get">item.get</a>('title', ['No title available'])[0],<br>            'authors': ', '.join([f"{<a href="http://author.get">author.get</a>('given', '')} {<a href="http://author.get">author.get</a>('family', '')}" for author in <a href="http://item.get">item.get</a>('author', [])]),<br>            'year': <a href="http://item.get">item.get</a>('published', {}).get('date-parts', [[None]])[0][0],<br>            'citations': <a href="http://item.get">item.get</a>('is-referenced-by-count', 0),<br>            'doi': <a href="http://item.get">item.get</a>('DOI', 'Not available'),<br>            'url': <a href="http://item.get">item.get</a>('URL', 'Not available'),<br>            'abstract': <a href="http://item.get">item.get</a>('abstract', 'Not available'),<br>            'publisher': <a href="http://item.get">item.get</a>('publisher', 'Not available'),<br>            'publication': <a href="http://item.get">item.get</a>('container-title', ['Not available'])[0],'journal_type': <a href="http://item.get">item.get</a>('type', 'Not available')  # Publication type (article, book, etc.)<br>        }<br><br>        return pub_info<br>    else:<br>        return None<br><br>Example usage with a DOI<br>doi = "<a href="tel:10.1000">10.1000</a>/journal.<a href="tel:123456">123456</a>"  # Replace with an actual DOI<br>publication = get_publication_by_doi(doi)<br><br>if publication:<br>    for key, value in <a href="http://publication.items">publication.items</a>():<br>        print(f'{key}: {value}')<br>else:<br>    print("No publication found for the given DOI.")<br>```<br><br></body></html>